---
title: "test_functions"
author: "Hugo Morvan"
date: "`r Sys.Date()`"
output: html_document
---

```{r warning=FALSE}
library(sparklyr)
library(dplyr)
```


```{r}
data <- read.csv("C:/Users/hugom/Desktop/CAMEO/Code/sesar_dummy_100.csv")
#colnames(data)
conf <- spark_config()
conf$`sparklyr.shell.driver-memory`<- "20G"
conf$spark.memory.fraction <- 0.7
conf$`sparklyr.cores.local` <- 4
conf$`spark.local.dir` <- "C:/Users/hugom/Desktop/Spark/"
spark_set_checkpoint_dir(sc, "C:/Users/hugom/Desktop/Spark/" ) # For stack overflow issues, checkpoint at every iteration. BUT the folder needs to be HDFS compatible
sc = spark_connect(master = "local", config = conf)

```

```{r}
sdf <- spark_read_csv(sc, name = "data", path = "C:/Users/hugom/Desktop/CAMEO/Code/sesar_dummy_100.csv") %>%  select(all_of(c("IV_Height", "IV_Weight", "IV_AHI", "IV_ODI","IV_Depression")))
```


```{r}
var_names <- colnames(sdf)
print(var_names)
var_types <- c("Continuous_int","Continuous_int","Continuous_int","Continuous_int","Binary")

```

```{r}
add_missing_values <- function(df, percent_added) {
# Initialize the "where" matrix with FALSE values (same dimensions as df)
  where_matrix <- matrix(FALSE, nrow = nrow(df), ncol = ncol(df))
  for (j in 1:ncol(df)) {
    observed_values <- sum(!is.na(df[, j]))
    additional_na_count <- round(percent_added * observed_values)
    if (additional_na_count > 0) {
      non_na_indices <- which(!is.na(df[, j]))
      additional_na_count <- min(additional_na_count, length(non_na_indices))
      if (additional_na_count > 0) {
        indices_to_mark <- sample(non_na_indices, additional_na_count)                                    
        where_matrix[indices_to_mark, j] <- TRUE
      }
    }
  }
  return(where_matrix)                                                                                
}

data <- sdf %>% collect()
where_mat <- add_missing_values(data, 0.1)
data_holy <- data
data_holy[where_mat] <- NA
#head(data_holy)
sdf_missing <- sdf_copy_to(sc, data_holy)
#normalized_df <- normalize_features(sdf_missing, c("IV_Height", "IV_Weight", "IV_AHI", "IV_ODI"), p = 2)
```


```{r}
analysis_formula <- as.formula("IV_Depression ~ IV_Height")

res <- bigMice::mice.spark(data = sdf_missing,
                           data_true = sdf,
                           sc = sc,
                           variable_types = var_types,
                           analysis_formula = analysis_formula,
                           predictorMatrix = NULL,
                           m = 2,
                           maxit = 5)
```

